{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../ucl_irdm2017_project2_group1\"))\n",
    "\n",
    "from ltr.data_load import make_rank_data_csv\n",
    "import ltr.dnn_utils\n",
    "import ltr.evals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import tensorflow as tf \n",
    "from IPython.core.display import clear_ouptput\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "##### - Load in the data and write to csvs\n",
    "##### - Take in the features and normalise, scaling from 0-1\n",
    "##### - Remove outlier querys with very high or low associated documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify the fold from the MSLR-10K dataset you wish to import \n",
    "fpath = '../../input/'\n",
    "fold_no = 1\n",
    "dataset = ['train', 'vali', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = make_rank_data_csv(fpath, fold_no, 'train')\n",
    "vali = make_rank_data_csv(fpath, fold_no, 'vali')\n",
    "test = make_rank_data_csv(fpath, fold_no, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a dataset of all data for normalisation and reset indices\n",
    "full_data = pd.concat([train,vali,test])\n",
    "full_data.index = range(full_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get list of unique query ids \n",
    "unique_qry = full_data[\"query_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each q_id, count the number of doucments \n",
    "num_docs= []\n",
    "for i in unique_qry:\n",
    "    num_docs.append(full_data[full_data['query_id']==i].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find stats about features in order to normalise\n",
    "mean_params = []\n",
    "max_params = []\n",
    "min_parms = []\n",
    "\n",
    "for q_id in unique_qry:\n",
    "    query = full_data[full_data['query_id'] == q_id].drop(['label', 'query_id'], axis=1)\n",
    "    average = list(query.mean())\n",
    "    max_values = list(query.max())\n",
    "    min_values = list(query.min())\n",
    "    mean_params.append([q_id] + average)\n",
    "    max_params.append([q_id] + max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(average, max_values, min_values, mean_params, max_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_cleaned = pd.DataFrame(mean_params)\n",
    "mean_cleaned.columns = [\"query_id\"] + [\"mean_\" + col for col in cleaned.columns[3:]]\n",
    "\n",
    "max_cleaned = pd.DataFrame(max_params)\n",
    "max_cleaned.columns = [\"query_id\"] + [\"max_\" + col for col in cleaned.columns[3:]]\n",
    "\n",
    "min_cleaned = pd.DataFrame(min_params)\n",
    "min_cleaned.columns = [\"query_id\"] + [\"m_\" + col for col in cleaned.columns[3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising the features by query parititons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_features = []\n",
    "\n",
    "for index,row in enumerate(cleaned.iterrows()):\n",
    "    \n",
    "    # Getting Query ID\n",
    "    q_id = row[1]['query_id']\n",
    "    \n",
    "    # Normalisation formula: 2*(x - min)/(max - min) - 1\n",
    "    norm_row = np.array(2*((np.array(row[1][3:]) - \\\n",
    "    np.array(min_cleaned[min_cleaned[\"query_id\"]==q_id].drop([\"query_id\"],axis=1))[0])) / \\\n",
    "    ((np.array(max_cleaned[max_cleaned[\"query_id\"] == q_id].drop([\"query_id\"],axis=1))[0]) - \\\n",
    "    (np.array(min_cleaned[min_cleaned[\"query_id\"] == q_id].drop([\"query_id\"],axis=1))[0]))-([1]*136))\n",
    "    \n",
    "    # Nans indicate division by zero, which means max == min, so setting to zero, Naive fix\n",
    "    norm_row[np.isnan(norm_row)] = 0.0\n",
    "    norm_features.append([q_id] + list(norm_row))\n",
    "    if index%10000 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pandas dataframe from normalised data, adding label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_cleaned = pd.DataFrame(norm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_cleaned.insert(0,'label', cleaned['label'])\n",
    "norm_cleaned.insert(0,'Unnamed: 0', cleaned['Unnamed: 0'])\n",
    "norm_cleaned.columns = cleaned.columns\n",
    "del norm_cleaned['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "a[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data back into train / validation / test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_train = norm_cleaned.iloc[0:723412]\n",
    "clean_val = norm_cleaned.iloc[723412:723412+235259]\n",
    "clean_test = norm_cleaned.iloc[723412+235259:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Getting Filter Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_train_filtered.to_csv(\"Data/Full_Deep_Youtube_Data/normalised_mslr_train_filtered_fld1.csv\", index=False)\n",
    "clean_val_filtered.to_csv(\"Data/Full_Deep_Youtube_Data/normalised_mslr_vali_filtered_fld1.csv\", index=False)\n",
    "\n",
    "clean_train.to_csv(\"Data/Full_Deep_Youtube_Data/normalised_mslr_train_fld1.csv\", index=False)\n",
    "clean_val.to_csv(\"Data/Full_Deep_Youtube_Data/normalised_mslr_vali_fld1.csv\", index=False)\n",
    "clean_test.to_csv(\"Data/Full_Deep_Youtube_Data/normalised_mslr_test_fld1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
